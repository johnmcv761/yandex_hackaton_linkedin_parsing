{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dc81oNMGj0m",
        "outputId": "689e2321-982e-4da1-f612-92d0547f18ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (4.10.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
            "Requirement already satisfied: outcome in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
            "Requirement already satisfied: idna in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br2QmmVY0QVd",
        "outputId": "ec15a73d-04ff-4cb4-c709-424613a32a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvirtualdisplay in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwFRy7hDUhr5",
        "outputId": "ff313766-f5ee-4ee2-b241-21d2a7a0ab54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: undetected_chromedriver in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (3.5.0)\n",
            "Requirement already satisfied: websockets in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (11.0.3)\n",
            "Requirement already satisfied: requests in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (2.28.1)\n",
            "Requirement already satisfied: selenium>=4.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (4.10.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (2022.9.14)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (0.22.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (0.10.3)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from requests->undetected_chromedriver) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from requests->undetected_chromedriver) (2.0.4)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.10)\n",
            "Requirement already satisfied: outcome in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.15.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (21.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.1.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected_chromedriver) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install undetected_chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_JcnljZHytpT"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
        "\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import pyvirtualdisplay\n",
        "import platform\n",
        "\n",
        "USER_LOGIN = 'johnmc76@mail.ru'\n",
        "USER_PASSWORD = 'Losangeles2022'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "caps = DesiredCapabilities().CHROME\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "caps['pageLoadStrategy'] = 'eager'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "options = webdriver.ChromeOptions()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "options.add_argument('enable-automation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# options.add_argument(\"--no-sandbox\")\n",
        "# options.add_argument(\"--disable-setuid-sandbox\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Opening linkedIn's login page\n",
        "# NOTE: We need to turn of 2 step authentification\n",
        "driver.get(\"https://linkedin.com/uas/login\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# waiting for the page to load\n",
        "time.sleep(3.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# entering username\n",
        "username = driver.find_element(By.ID, \"username\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# In case of an error, try changing the element\n",
        "# tag used here.\n",
        "\n",
        "# Enter Your Email Address\n",
        "username.send_keys(USER_LOGIN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# entering password\n",
        "pword = driver.find_element(By.ID, \"password\")\n",
        "# In case of an error, try changing the element\n",
        "# tag used here.\n",
        "\n",
        "# Enter Your Password\n",
        "pword.send_keys(USER_PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clicking on the log in button\n",
        "# Format (syntax) of writing XPath -->\n",
        "# //tagname[@attribute='value']\n",
        "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
        "\n",
        "### TEST for parsing page with posts\n",
        "# get_and_print_profile_info(driver, 'https://www.linkedin.com/in/mathurin-ache-11004218')\n",
        "\n",
        "# exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Open search page\n",
        "driver.get('https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=1gy')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "profile_urls = []\n",
        "\n",
        "NUM_PAGES_TO_PARSE = 12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Iterate over pages of search results\n",
        "# to collect profile urls\n",
        "for i in range(NUM_PAGES_TO_PARSE):\n",
        "    search_result_links = driver.find_elements(By.CSS_SELECTOR, \"div.entity-result__item a.app-aware-link\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "for link in search_result_links:\n",
        "    href = link.get_attribute(\"href\")\n",
        "    if 'linkedin.com/in' in href:\n",
        "        profile_urls.append(href)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "next_button = driver.find_element(By.CLASS_NAME,'artdeco-pagination__button--next')\n",
        "next_button.click()\n",
        "time.sleep(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.linkedin.com/in/smyslovmax?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMS23IBAVkav9US1aXWoJPTTwD4VlXFR74', 'https://www.linkedin.com/in/ACoAABBvLXkByegTJ0lFRJGVdH48S245yErzTW0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABBvLXkByegTJ0lFRJGVdH48S245yErzTW0', 'https://www.linkedin.com/in/bogdan-p-s?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACdU_WIBNQjnbFU1nSTsASrmDX4rzSst_xc', 'https://www.linkedin.com/in/antony-vasilev?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADZMkhcBkXFo7WT9DijWUzVB-B_HvDjJIuo', 'https://www.linkedin.com/in/yuzhakov-max?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADy3YEYBewXnnqECpgOs5rs29mTeosCSGlo', 'https://www.linkedin.com/in/ACoAAER08mEBzfsrkPEW4fN-KgPDRgE6EMsFiR4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAER08mEBzfsrkPEW4fN-KgPDRgE6EMsFiR4', 'https://www.linkedin.com/in/denis-dzera-b26134195?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC3CcE4Bzlbms9sXLlQcuQLNea0HJcnkFBw', 'https://www.linkedin.com/in/ACoAAAvUn9kBqlTUtaPRtWxJ4CEkj6ka7_Hlwf8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAvUn9kBqlTUtaPRtWxJ4CEkj6ka7_Hlwf8', 'https://www.linkedin.com/in/ivan-gorbunov-h?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC1tgdgBXWwHtDgIgDyfNZGBqvukcSGhc4g', 'https://www.linkedin.com/in/ACoAACW81EYBy1zqmnrQNnmELgseESbikNJ8yyo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACW81EYBy1zqmnrQNnmELgseESbikNJ8yyo', 'https://www.linkedin.com/in/vladimir-aperyan?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABvzpcoB_sfQx4Oykcwus5fQlCdeM2fQB7A', 'https://www.linkedin.com/in/svit?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB33j0UBKXEyrKc-Dwnv6pete8WoXlGPynU', 'https://www.linkedin.com/in/anechiporenko?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABx0lmoBcthPwMMHEMPcl_mZQ1brUjnJXdY', 'https://www.linkedin.com/in/meffazm?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADC40OgBcNbVsr02FzlvnKxDnPBVGZL0Stg']\n",
            "Name --> Maxim Smyslov \n",
            "Works At --> Data Scientist at Mars\n",
            "https://www.linkedin.com/in/smyslovmax/\n",
            "Number of posts: 0\n",
            "Name --> Александр Иванов \n",
            "Works At --> Data Science/ Data Scientist/ Data Analyst\n",
            "https://www.linkedin.com/in/%D0%B0%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80-%D0%B8%D0%B2%D0%B0%D0%BD%D0%BE%D0%B2-13540978/\n",
            "Number of posts: 5\n",
            "Post text: а вот и он, очередной диплом =))\n",
            "Reactions: Elina Ivanova и еще 27 участников\n",
            "Post text: Kate Sibrikova, спасибо за огромный вклад! Благодаря тебе наша команда смогла попасть в топ-25% лидерборда!\n",
            "Reactions: 9\n",
            "Post text: Посетил очень интересное и необычное для меня мероприятие #truetechday от #МТС. Направления конференции: #DS , #DE , #DAПоразило несколько моментов:1. Размах. Был от работы на похожих мероприятиях. Нет, это даже было не близко. Тут МТС решили максимально вложиться в самопиар. Продемонстрировать, у компании дела идут хорошо, максимально уходят от шаблона, МТС теперь не просто мобильный оператор, а полноценная экосистема.2. Все спикеры, начиная с президента компании, максимально соответствовали аудитории. Никаких костюмов, галстуков. Джинсы, толстовка, кроссовки. 3. Выступления президента МТС Вячеслава Николаева (всё, все отчества из всех расписаний уже пропали, только имя и фамилия) и исполнительного директора по стратегии и инновациям Евгения Черешнева были супер. Конференцию начали с козырей. Ярко, живо, интересно, в какой-то момент я задумался: \"а что у меня из продуктов мтс, так, домашний интернет, может уйти к ним с мегафона и банк основной с тинька на мтс поменять?\" Потом этот гипноз уже скинул с себя 😁 4. Много интересных выступлений, проблем направления DS. Достижений, а так же результатов разработок. Причем радует, что все слова уже понятны 😆 5. ChatGPT. Наверное, 40% докладов сводилось к нему. Стоит бояться или нет? Использовать в работе? Захватит ли он мир? Настолько ли он сложен и неповторим? Все спикеры хотели высказаться о самой живой теме и получилось, что говорили в основном о нем на многих выступлениях. PS: по мнению одного из спикеров, ждем в мая отечественный аналог6. Сама организация от МТС. Великолепно. Нигде нет очередей, всё быстро, продуманно. 7. Выступления. Ребята очень живо делились своими разработками, проблемами, чего добились и к каким результатам пришли. После мероприятия обсуждали один момент, а кто целевая аудитория этой конференции? Будний день, основная масса на работе, целенаправленно отправлять сотрудников на промо конференцию от конкурентов, которые ещё и перехватить могут, вряд ли. Значит привлечение тех, кто в поиске?\n",
            "Reactions: Elina Ivanova и еще 17 участников\n",
            "Post text: «Давайте будем честны. 91% западных компаний все еще находятся в России и делают то, что разумно: ждут, сдерживают риски, защищают активы», — Глава МИД АвстрииУ Австрии своя статистика, очень похожая на статистику в РФ, 91% компаний остался, но почему почти всех моих знакомых, кто работал в дочка западных компаний, сократили? Кто-то быстро сдался, кто-то старался до конца. Мы следили за каждым пакетом, которые кто-то складывал в другие пакеты.Изучали досконально, пытаясь понять формулировки, сами европейцы их и не понимали. В начале были проблемы с поставками. Никто не понимал, можно/нельзя или если очень хочется, то можно. Первый пакет, второй, третий... Поиск новых путей логистики, срыв сроков поставки, замена оборудования в процессе изготовления, поиск местных комплектующих. Вроде, жить можно, работа кипит... И вот тут пришел 7й пакет. Нечеткие формулировки: куда можно поставлять, куда нельзя, что такое для промышленности, а что нет, завод или индустрия... Никто не мог ответить. Юристы в Европе разводили руками. Все западные госорганы просто напуганы даже перспективой взаимодействия с Россией. Говорят, бизнес и ничего личного. Нет. Это так не работает. Бизнес -  это личное. Это люди. Это эмоции!Все пытались сохранить бизнес. Менеджмент компании отстаивает офис  в РФ до последнего. Понедельник. Утренние собрание. Участвует много менеджеров из Европы. Ничего хорошего нам не скажут. Именно так. Наша компания, как и многие другие, приняла решение уходить с рынка в РФ. Шок. Даже если понимаешь, что к этому идет, всё равно нельзя быть готовым. Запуск процесса, менеджмент согласует сроки, волны сокращений, размер пособий - время ещё есть.Компания помогла людям максимально - открывали позиции в Европе. Многие коллеги решились на релокацию. Сложные пути, через Эмираты из России в Европу. Я тоже пытался. Получил оффер, но, взвесив все за и против, остался в РФ.Спасибо европейскому менеджменту, а так же руководству офиса в России, расстались достойно. Культура в европейских компаниях на высоте и это то, чему надо у них учиться. Последний день. Вторник. Знал заранее, но всё равно опять шок. 3 классных года в компании, я не обновлял резюме, не искал работу, если мне звонили hr, то отвечал честно \"мне не интересно, но присылайте описание, перекину коллегам по профилю\".Где-то между первым понедельником и заключительным вторником надо было думать, что делать дальше, а дальше...\n",
            "Reactions: 28\n",
            "Post text: так при любом старте =)\n",
            "Reactions: 5\n",
            "Name --> Bogdan Sukhoronchack \n",
            "Works At --> Data scientist / data analyst\n",
            "https://www.linkedin.com/in/bogdan-p-s/\n",
            "Number of posts: 0\n",
            "Name --> Anton Vasilev \n",
            "Works At --> Data scientist\n",
            "https://www.linkedin.com/in/antony-vasilev/\n",
            "Number of posts: 0\n",
            "Name --> Maksim Yuzhakov \n",
            "Works At --> Data Scientist | Data Analyst\n",
            "https://www.linkedin.com/in/yuzhakov-max/\n",
            "Number of posts: 0\n",
            "Name --> Станислав Сигарёв \n",
            "Works At --> --\n",
            "https://www.linkedin.com/in/freazer/\n",
            "Number of posts: 0\n",
            "Name --> Denis Dzera \n",
            "Works At --> Data Scientist at Sber\n",
            "https://www.linkedin.com/in/denis-dzera-b26134195/\n",
            "Number of posts: 0\n",
            "Name --> Timur Salakhetdinov \n",
            "Works At --> Financial Data Analyst | SQL | Tableau | TMT Industry | Developed projects for Mobile TeleSystems\n",
            "https://www.linkedin.com/in/stimur/\n",
            "Number of posts: 9\n",
            "Post text: Super excited to share 🎉 that I recently had the pleasure of participating in two enriching workshops at YANDEX PRACTICUM 🚀. The Yandex Market Hackathon 🧠 was a thrilling ride, providing me with my first real-world, cross-functional experience in Data Science 👩‍💻. Our team's spirit 🤝 was truly extraordinary, with everyone committed to helping each other.For the Yandex Market Hackathon https://lnkd.in/dxUzzEmv 📦, our goal was to create an ML product for the Yandex Market service packer. Through collaboration, we preprocessed large volumes of raw data 💽, developing a Machine Learning model that efficiently estimated the best packaging methods. I took up a key role in designing a service algorithm and packer interface for the ML model 🛠️, focusing on packaging solutions optimization. As a result, we noticed a significant improvement in packaging efficiency ✅, positively impacting Yandex Market's operational performance 📈.In another project, LinkedIn Vacancies Analysis 🕵️‍♂️, I developed an automated solution to parse LinkedIn vacancies in the Data Analytics field using BeautifulSoup. The initiative aimed to provide deeper insights into market trends and job requirements 🔍. Ensuring data consistency and accuracy, I transformed raw scraped data and prepared it for visualization 🖥️. I also created an interactive dashboard https://lnkd.in/dSxCPqsi using Tableau, which helped identify key skills in demand and map out the competitive landscape in the Data Analytics job market 📊.Having tasted the thrill and impact of working in data-driven projects 💪, I am  ready to dive headfirst into new opportunities. I am actively seeking roles in Data Analysis or Data Science 🎯. With two years of analytics experience under my belt, coupled with my passion for deriving insights from data, I am ready to contribute my skills to a new team and embrace fresh challenges 🌟.I'd greatly appreciate any advice or opportunities you may have to share 🙏. Thank you in advance for your support! 😉 #dataanalysis #datascience #visualization #tableau #machinelearning #opportunities #job #thankyou\n",
            "Reactions: Oksana Solomentseva и еще 1 участник\n",
            "Post text: As an ambitious Data Analyst, my mission is to refine my skill set and knowledge within this exciting field 👨‍💻. I've recently earned my diploma from the esteemed Yandex Practicum coding bootcamp, specializing in \"Data Analysis\" 💻. This rigorous program has been instrumental in furnishing me with a wealth of experience across a broad spectrum of areas including data preprocessing, exploratory data analysis, business analytics, and cohort analysis using SQL and Python. Additionally, I've honed my skills in A/B testing and visualization through Tableau. This unique blend of training has been indispensable in shaping my understanding of the analytical landscape and has provided me with the tools necessary to tackle complex data-driven problems.I was impressed by the depth and breadth of the skills 🎓 I've developed. I learned the importance of data preprocessing, and how clean, well-structured data is the foundation of accurate analysis. I also deepened my understanding of the importance of exploratory data analysis in identifying trends and patterns, as well as the powerful insights business analytics and cohort analysis can offer. Finally, I realized that A/B testing isn't just about finding out what works best - it's about understanding why it works best, and applying these findings strategically.Upon finishing 🏁 the Yandex Practicum coding bootcamp I'm grateful for the rigorous training I received through the Yandex Practicum and excited for the opportunities it has opened up for me. The journey of learning never stops, and I can't wait to take my next steps in this exhilarating field of Data Analysis.#dataanalysis #businessanalytics #python #visualization #data #tableau #sql #learning\n",
            "Reactions: 4\n",
            "Post text: I recently found out about a website ADPList,  which allows people to get free mentorship to boost their professional careers. I had a great session with Younes Sandi! We talked about how to get into Data Science field and he gave me a lot of useful tips. Short session of 30 minutes was really helpful, I now have more clear understanding of the path to take. Younes is very approachable and professional. I recommend ADPList to everyone to find great mentor. #datascience #careers #people\n",
            "Reactions: 5\n",
            "Post text: My Father-in-law sent me this article from Forbes yesterday. Here is a quote from the article that was my main takeaway:\"In fact, as AI becomes more accessible and mainstream, that team (analytics) may well become even more critical to the business than it already is. What is beyond doubt, though, is that their jobs will substantially change.\"The world is changing and we need to adapt with it. Data Analytics is undoubtedly going to change in the next 5-10 years as it adapts to new innovations.Learn the fundamentals now. Learn the new skills being created tomorrow.\n",
            "Reactions: 1 364\n",
            "Post text: If you are looking for a great book about statistics that offers a fresh approach to presenting study material and helps you freshen up your knowledge, try OpenIntro Statistics https://lnkd.in/dP-ZDsdZ.What is great about it, is that it is an excellent and free resource for anyone looking to learn about statistics. Also it has an unique approach to presenting the material. Rather than overwhelming the reader with complex formulas and technical jargon, OpenIntro Statistics breaks down concepts in a clear and concise manner, making it accessible to everyone.Another great aspect of this book is the numerous tasks and exercises at the end of each section. These exercises help solidify the concepts covered in the section and give readers a chance to practice what they have learned. I found information about OpenIntro Statistics on a post made by Nick Singh 📕🐒 and recommend it too for anyone looking to learn more about statistics or freshen up their knowledge.#dataanalyst #datascientist #statistics #education\n",
            "Post text: According to the latest MIT study ChatGPT boosts productivity by 40% and quality by 20%. One of the most exciting findings from the study was that exposure to ChatGPT increased job satisfaction and self-efficacy. With the ability to enhance productivity, diminish inequality, and narrow the distribution of productivity, ChatGPT possesses the potential to bring about a revolutionary shift in the way we approach work, particularly within the realm of writing. By predominantly supplanting worker effort as opposed to simply supplementing worker skills, ChatGPT has reorganized task assignments to prioritize activities such as idea-generation and editing, while de-emphasizing the more rudimentary task of rough-drafting.How do you personally use ChatGPT? I think it really can help any professional increase their productivity, especially when you need to do a lot of drafts of text. With the help of ChatGPT, you get a first raw draft in 1 second! It’s just amazing how it works.Other use cases for me were to compare services on the web. It can create in an instant a table of all features available by 2-3 services.The last use case I would like to mention is that ChatGPT can substantially help with preparation for interviews.#productivity #writing #chatgpt #editing\n",
            "Reactions: 2\n",
            "Post text: As an aspiring Data Analyst, I am constantly striving to improve my skills and knowledge in the field 👨‍💻. Last year, I had the opportunity to participate in the Yandex Practicum coding bootcamp «Specialist in Data Science» 💻, where I gained invaluable experience in data cleaning, management, transformation, visualization, statistical and data analysis, and machine learning.Throughout the program, I learned various techniques and tools that have helped me enhance my skills and become a better Data Analyst. The hands-on projects and assignments gave me the chance to practice my skills and apply the knowledge I gained in real-world scenarios.One of the most significant takeaways from the program was learning how to handle and clean messy data. This is an essential skill for any Data Analyst, as working with raw and unorganized data can be a challenging task.The program was incredibly rigorous, but I'm grateful for the challenges it presented. By the end of the program, I felt confident in my ability to work with complex data sets and to use various tools and techniques to derive meaningful insights from them.Since completing the program, I'm excited to continue to grow and develop as a Data Analyst and currently continue my studies at Yandex Practicum «Data Analytics» bootcamp 😉.#machinelearning #datascience #dataanalysis #python #bootcamp #like\n",
            "Reactions: 2\n",
            "Post text: I just finished an updated Machine Learning Specialization! Thank you Andrew Ng and DeepLearning.AI for this wonderful opportunity! I think Andrew Ng is one of the best instructors, who easily explains complex topics about ML. This is a foundational program on ML, so if you want to improve the understanding of basic AI concepts, go for it. You will get a broad introduction to: - supervised learning (linear regression, logistic regression, gradient descent),- advanced algorithms (neural networks, decision trees)- unsupervised learning (clustering, anomaly detection, PCA), recommender systems, reinforcement learning.I hope that you will have same fun, exploring this course, if you choose it too!#datascientist #dataanalyst #machinelearning #deeplearning #ai #neuralnetworks #thankyou #learning\n",
            "Reactions: 2\n",
            "Name --> Иван Горбунов \n",
            "Works At --> Data Scientist – MTS\n",
            "https://www.linkedin.com/in/ivan-gorbunov-h/\n",
            "Number of posts: 0\n",
            "Name --> Fedor Mushenok \n",
            "Works At --> ML developer at Yandex\n",
            "https://www.linkedin.com/in/fedor-mushenok/\n",
            "Number of posts: 3\n",
            "Post text: Hi everyone - I am looking for a new role and would appreciate your support. Thank you in advance for any connections, advice, or opportunities you can offer. #OpenToWork\n",
            "Reactions: 19\n",
            "Post text: #inspiration #philips\n",
            "Reactions: 2\n",
            "Name --> Владимир Аперян \n",
            "Works At --> Data Scientist\n",
            "https://www.linkedin.com/in/vladimir-aperyan/\n",
            "Number of posts: 0\n",
            "Name --> Svyatoslav Emelyanenko \n",
            "Works At --> Data Scientist – Газпромбанк\n",
            "https://www.linkedin.com/in/svit/\n",
            "Number of posts: 0\n",
            "Name --> Анастасия Нечипоренко \n",
            "Works At --> Data Scientist\n",
            "https://www.linkedin.com/in/anechiporenko/\n",
            "Number of posts: 1\n",
            "Post text: My first step into the world of data science :)\n",
            "Reactions: 13\n",
            "Name --> Dmitrii Velibekov \n",
            "Works At --> Data Scientist at OTP Bank\n",
            "https://www.linkedin.com/in/meffazm/\n",
            "Number of posts: 3\n",
            "Reactions: 2\n",
            "Reactions: 4\n",
            "Reactions: 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "profile_urls = list(set(profile_urls))\n",
        "\n",
        "print(profile_urls)\n",
        "\n",
        "# Parse profile urls\n",
        "for profile_url in profile_urls:\n",
        "    get_and_print_profile_info(driver, profile_url)\n",
        "    time.sleep(2)\n",
        "\n",
        "# close the Chrome browser\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_and_print_profile_info(driver, profile_url):\n",
        "    driver.get(profile_url)        # this will open the link\n",
        "\n",
        "    # Extracting data from page with BeautifulSoup\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml')\n",
        "\n",
        "    # Extracting the HTML of the complete introduction box\n",
        "    # that contains the name, company name, and the location\n",
        "    intro = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
        "\n",
        "    #print(intro)\n",
        "\n",
        "    # In case of an error, try changing the tags used here.\n",
        "    name_loc = intro.find(\"h1\")\n",
        "\n",
        "    # Extracting the Name\n",
        "    name = name_loc.get_text().strip()\n",
        "    # strip() is used to remove any extra blank spaces\n",
        "\n",
        "    works_at_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
        "\n",
        "    # this gives us the HTML of the tag in which the Company Name is present\n",
        "    # Extracting the Company Name\n",
        "    works_at = works_at_loc.get_text().strip()\n",
        "\n",
        "    print(\"Name -->\",  name,\n",
        "          \"\\nWorks At -->\", works_at)\n",
        "\n",
        "    POSTS_URL_SUFFIX = 'recent-activity/all/'\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    # Get current url from browser\n",
        "    cur_profile_url = driver.current_url\n",
        "    print(cur_profile_url)\n",
        "\n",
        "    # Parse posts\n",
        "    get_and_print_user_posts(driver, cur_profile_url + POSTS_URL_SUFFIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\1837785477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_profile_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\4143096644.py\u001b[0m in \u001b[0;36mget_and_print_profile_info\u001b[1;34m(driver, profile_url)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# In case of an error, try changing the tags used here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mname_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Extracting the Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
          ]
        }
      ],
      "source": [
        "get_and_print_profile_info(driver, profile_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_and_print_profile_info(driver, profile_url):\n",
        "    time.sleep(random.uniform(0,2))\n",
        "\n",
        "    driver.get(profile_url)        # this will open the link\n",
        "\n",
        "    # Extracting data from page with BeautifulSoup\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml') # 'lxml'  \"html.parser\"\n",
        "\n",
        "    # Extracting the HTML of the complete introduction box\n",
        "    # that contains the name, company name, and the location\n",
        "    intro = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
        "\n",
        "    #print(intro)\n",
        "\n",
        "    # In case of an error, try changing the tags used here.\n",
        "    name_loc = intro.find(\"h1\")\n",
        "\n",
        "    # Extracting the Name\n",
        "    name = name_loc.get_text().strip()\n",
        "    # strip() is used to remove any extra blank spaces\n",
        "\n",
        "    works_at_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
        "\n",
        "    # this gives us the HTML of the tag in which the Company Name is present\n",
        "    # Extracting the Company Name\n",
        "    works_at = works_at_loc.get_text().strip()\n",
        "\n",
        "    print(\"Name -->\",  name,\n",
        "          \"\\nWorks At -->\", works_at)\n",
        "\n",
        "    POSTS_URL_SUFFIX = 'recent-activity/all/'\n",
        "\n",
        "    time.sleep(random.uniform(2,4))\n",
        "\n",
        "    # Get current url from browser\n",
        "    cur_profile_url = driver.current_url\n",
        "    print(cur_profile_url)\n",
        "\n",
        "    # Parse posts\n",
        "    posts = get_and_print_user_posts(driver, cur_profile_url + POSTS_URL_SUFFIX)\n",
        "    \n",
        "    return name, works_at, posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\1837785477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_profile_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\3012557116.py\u001b[0m in \u001b[0;36mget_and_print_profile_info\u001b[1;34m(driver, profile_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# In case of an error, try changing the tags used here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mname_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Extracting the Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
          ]
        }
      ],
      "source": [
        "get_and_print_profile_info(driver, profile_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qyTOHOUtzwNk"
      },
      "outputs": [],
      "source": [
        "def get_and_print_user_posts(driver, posts_url):\n",
        "    driver.get(posts_url)\n",
        "\n",
        "    #Simulate scrolling to capture all posts\n",
        "    SCROLL_PAUSE_TIME = 1.5\n",
        "\n",
        "    # Get scroll height\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "    # We can adjust this number to get more posts\n",
        "    NUM_SCROLLS = 5\n",
        "\n",
        "    for i in range(NUM_SCROLLS):\n",
        "        # Scroll down to bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "        # Wait to load page\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "        # Calculate new scroll height and compare with last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "        last_height = new_height\n",
        "\n",
        "    # Parsing posts\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml')\n",
        "    # soup.prettify()\n",
        "\n",
        "    posts = soup.find_all('li', class_='profile-creator-shared-feed-update__container')\n",
        "    # print(posts)\n",
        "\n",
        "    print(f'Number of posts: {len(posts)}')\n",
        "    for post_src in posts:\n",
        "        post_text_div = post_src.find('div', {'class': 'feed-shared-update-v2__description-wrapper mr2'})\n",
        "\n",
        "        # if post_text_div is None:\n",
        "        #     print(post_src)\n",
        "\n",
        "        if post_text_div is not None:\n",
        "            post_text = post_text_div.find('span', {'dir': 'ltr'})\n",
        "        else:\n",
        "            post_text = None\n",
        "\n",
        "        # If post text is found\n",
        "        if post_text is not None:\n",
        "            post_text = post_text.get_text().strip()\n",
        "            print(f'Post text: {post_text}')\n",
        "\n",
        "        reaction_cnt = post_src.find('span', {'class': 'social-details-social-counts__reactions-count'})\n",
        "\n",
        "        # If number of reactions is written as text\n",
        "        # It has different class name\n",
        "        if reaction_cnt is None:\n",
        "            reaction_cnt = post_src.find('span', {'class': 'social-details-social-counts__social-proof-text'})\n",
        "\n",
        "        if reaction_cnt is not None:\n",
        "            reaction_cnt = reaction_cnt.get_text().strip()\n",
        "            print(f'Reactions: {reaction_cnt}')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'posts_url' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\4129543028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_user_posts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposts_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'posts_url' is not defined"
          ]
        }
      ],
      "source": [
        "get_and_print_user_posts(driver, posts_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "PYmDuQr2z7q4",
        "outputId": "b4a25b5d-b93c-4b70-acc5-07bc7f4f1240"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'selenium.webdriver' has no attribute 'ChromOptions'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\3169853951.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcaps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pageLoadStrategy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'eager'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChromOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enable-automation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#options.add_argument(\"--no-sandbox\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'selenium.webdriver' has no attribute 'ChromOptions'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # start Chrome browser\n",
        "    caps = DesiredCapabilities().CHROME\n",
        "\n",
        "    caps['pageLoadStrategy'] = 'eager'\n",
        "\n",
        "    options = webdriver.ChromOptions()\n",
        "    options.add_argument('enable-automation')\n",
        "    #options.add_argument(\"--no-sandbox\")\n",
        "    #options.add_argument(\"--disable-setuid-sandbox\")\n",
        "\n",
        "    driver = webdriver.Chrome(options = options)\n",
        "\n",
        "    # Opening linkedIn's login page\n",
        "    # NOTE: We need to turn of 2 step authentification\n",
        "    driver.get(\"https://linkedin.com/uas/login\")\n",
        "\n",
        "    # waiting for the page to load\n",
        "    time.sleep(3.5)\n",
        "\n",
        "    # entering username\n",
        "    username = driver.find_element(By.ID, \"username\")\n",
        "\n",
        "    # In case of an error, try changing the element\n",
        "    # tag used here.\n",
        "\n",
        "    # Enter Your Email Address\n",
        "    username.send_keys(USER_LOGIN)\n",
        "\n",
        "    # entering password\n",
        "    pword = driver.find_element(By.ID, \"password\")\n",
        "    # In case of an error, try changing the element\n",
        "    # tag used here.\n",
        "\n",
        "    # Enter Your Password\n",
        "    pword.send_keys(USER_PASSWORD)\n",
        "\n",
        "    # Clicking on the log in button\n",
        "    # Format (syntax) of writing XPath -->\n",
        "    # //tagname[@attribute='value']\n",
        "    driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
        "\n",
        "    ### TEST for parsing page with posts\n",
        "    # get_and_print_profile_info(driver, 'https://www.linkedin.com/in/mathurin-ache-11004218')\n",
        "\n",
        "    # exit()\n",
        "\n",
        "    # Open search page\n",
        "    driver.get('https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=1gy')\n",
        "\n",
        "    profile_urls = []\n",
        "\n",
        "    NUM_PAGES_TO_PARSE = 12\n",
        "\n",
        "    # Iterate over pages of search results\n",
        "    # to collect profile urls\n",
        "    for i in range(NUM_PAGES_TO_PARSE):\n",
        "        search_result_links = driver.find_elements(By.CSS_SELECTOR, \"div.entity-result__item a.app-aware-link\")\n",
        "\n",
        "        for link in search_result_links:\n",
        "            href = link.get_attribute(\"href\")\n",
        "            if 'linkedin.com/in' in href:\n",
        "                profile_urls.append(href)\n",
        "\n",
        "        next_button = driver.find_element(By.CLASS_NAME,'artdeco-pagination__button--next')\n",
        "        next_button.click()\n",
        "        time.sleep(2)\n",
        "\n",
        "\n",
        "    profile_urls = list(set(profile_urls))\n",
        "\n",
        "    print(profile_urls)\n",
        "\n",
        "    # Parse profile urls\n",
        "    for profile_url in profile_urls:\n",
        "        get_and_print_profile_info(driver, profile_url)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # close the Chrome browser\n",
        "    driver.quit()"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 6869,
        "start_time": "2023-06-26T09:53:26.717Z"
      },
      {
        "duration": 52,
        "start_time": "2023-06-26T09:54:00.330Z"
      },
      {
        "duration": 3176,
        "start_time": "2023-06-26T09:54:06.302Z"
      },
      {
        "duration": 4421,
        "start_time": "2023-06-26T09:54:12.202Z"
      },
      {
        "duration": 299,
        "start_time": "2023-06-26T09:54:17.434Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-26T09:54:32.258Z"
      },
      {
        "duration": 28,
        "start_time": "2023-06-26T09:54:51.234Z"
      },
      {
        "duration": 1362,
        "start_time": "2023-06-26T09:55:45.641Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T09:58:27.798Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:27:42.712Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:28:15.154Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-26T10:28:37.419Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:28:43.796Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:28:51.407Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:08.234Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:51:25.096Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-26T10:51:30.127Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:51:35.208Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:39.600Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:44.939Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:50.421Z"
      },
      {
        "duration": 657,
        "start_time": "2023-06-26T10:52:26.923Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-26T10:53:02.146Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-26T10:54:04.427Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:54:10.406Z"
      },
      {
        "duration": 113,
        "start_time": "2023-06-26T10:57:42.853Z"
      },
      {
        "duration": 118,
        "start_time": "2023-06-26T10:57:49.217Z"
      }
    ],
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
