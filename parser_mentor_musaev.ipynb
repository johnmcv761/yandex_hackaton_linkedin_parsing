{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dc81oNMGj0m",
        "outputId": "689e2321-982e-4da1-f612-92d0547f18ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (4.10.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (1.26.11)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (2022.9.14)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium) (0.10.3)\n",
            "Requirement already satisfied: outcome in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
            "Requirement already satisfied: idna in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
            "Requirement already satisfied: sniffio in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br2QmmVY0QVd",
        "outputId": "ec15a73d-04ff-4cb4-c709-424613a32a19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvirtualdisplay in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install pyvirtualdisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwFRy7hDUhr5",
        "outputId": "ff313766-f5ee-4ee2-b241-21d2a7a0ab54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: undetected_chromedriver in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (3.5.0)\n",
            "Requirement already satisfied: websockets in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (11.0.3)\n",
            "Requirement already satisfied: requests in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (2.28.1)\n",
            "Requirement already satisfied: selenium>=4.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from undetected_chromedriver) (4.10.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (2022.9.14)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (0.22.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (0.10.3)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from selenium>=4.9.0->undetected_chromedriver) (1.26.11)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from requests->undetected_chromedriver) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from requests->undetected_chromedriver) (2.0.4)\n",
            "Requirement already satisfied: async-generator>=1.9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.10)\n",
            "Requirement already satisfied: outcome in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.15.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (21.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (1.1.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium>=4.9.0->undetected_chromedriver) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium>=4.9.0->undetected_chromedriver) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\evgeny.musaev\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium>=4.9.0->undetected_chromedriver) (0.14.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install undetected_chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_JcnljZHytpT"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
        "\n",
        "import time\n",
        "import re\n",
        "import random\n",
        "\n",
        "import os\n",
        "import logging\n",
        "import pyvirtualdisplay\n",
        "import platform\n",
        "\n",
        "USER_LOGIN = 'johnmc76@mail.ru'\n",
        "USER_PASSWORD = 'Losangeles2022'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "caps = DesiredCapabilities().CHROME\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "caps['pageLoadStrategy'] = 'eager'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "options = webdriver.ChromeOptions()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "options.add_argument('enable-automation')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# options.add_argument(\"--no-sandbox\")\n",
        "# options.add_argument(\"--disable-setuid-sandbox\")\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Opening linkedIn's login page\n",
        "# NOTE: We need to turn of 2 step authentification\n",
        "driver.get(\"https://linkedin.com/uas/login\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# waiting for the page to load\n",
        "time.sleep(3.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# entering username\n",
        "username = driver.find_element(By.ID, \"username\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# In case of an error, try changing the element\n",
        "# tag used here.\n",
        "\n",
        "# Enter Your Email Address\n",
        "username.send_keys(USER_LOGIN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# entering password\n",
        "pword = driver.find_element(By.ID, \"password\")\n",
        "# In case of an error, try changing the element\n",
        "# tag used here.\n",
        "\n",
        "# Enter Your Password\n",
        "pword.send_keys(USER_PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clicking on the log in button\n",
        "# Format (syntax) of writing XPath -->\n",
        "# //tagname[@attribute='value']\n",
        "driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
        "\n",
        "### TEST for parsing page with posts\n",
        "# get_and_print_profile_info(driver, 'https://www.linkedin.com/in/mathurin-ache-11004218')\n",
        "\n",
        "# exit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Open search page\n",
        "driver.get('https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=1gy')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "profile_urls = []\n",
        "\n",
        "NUM_PAGES_TO_PARSE = 12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Iterate over pages of search results\n",
        "# to collect profile urls\n",
        "for i in range(NUM_PAGES_TO_PARSE):\n",
        "    search_result_links = driver.find_elements(By.CSS_SELECTOR, \"div.entity-result__item a.app-aware-link\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "for link in search_result_links:\n",
        "    href = link.get_attribute(\"href\")\n",
        "    if 'linkedin.com/in' in href:\n",
        "        profile_urls.append(href)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "next_button = driver.find_element(By.CLASS_NAME,'artdeco-pagination__button--next')\n",
        "next_button.click()\n",
        "time.sleep(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.linkedin.com/in/smyslovmax?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADMS23IBAVkav9US1aXWoJPTTwD4VlXFR74', 'https://www.linkedin.com/in/ACoAABBvLXkByegTJ0lFRJGVdH48S245yErzTW0?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABBvLXkByegTJ0lFRJGVdH48S245yErzTW0', 'https://www.linkedin.com/in/bogdan-p-s?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACdU_WIBNQjnbFU1nSTsASrmDX4rzSst_xc', 'https://www.linkedin.com/in/antony-vasilev?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADZMkhcBkXFo7WT9DijWUzVB-B_HvDjJIuo', 'https://www.linkedin.com/in/yuzhakov-max?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADy3YEYBewXnnqECpgOs5rs29mTeosCSGlo', 'https://www.linkedin.com/in/ACoAAER08mEBzfsrkPEW4fN-KgPDRgE6EMsFiR4?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAER08mEBzfsrkPEW4fN-KgPDRgE6EMsFiR4', 'https://www.linkedin.com/in/denis-dzera-b26134195?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC3CcE4Bzlbms9sXLlQcuQLNea0HJcnkFBw', 'https://www.linkedin.com/in/ACoAAAvUn9kBqlTUtaPRtWxJ4CEkj6ka7_Hlwf8?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAAvUn9kBqlTUtaPRtWxJ4CEkj6ka7_Hlwf8', 'https://www.linkedin.com/in/ivan-gorbunov-h?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAC1tgdgBXWwHtDgIgDyfNZGBqvukcSGhc4g', 'https://www.linkedin.com/in/ACoAACW81EYBy1zqmnrQNnmELgseESbikNJ8yyo?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAACW81EYBy1zqmnrQNnmELgseESbikNJ8yyo', 'https://www.linkedin.com/in/vladimir-aperyan?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABvzpcoB_sfQx4Oykcwus5fQlCdeM2fQB7A', 'https://www.linkedin.com/in/svit?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAAB33j0UBKXEyrKc-Dwnv6pete8WoXlGPynU', 'https://www.linkedin.com/in/anechiporenko?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAABx0lmoBcthPwMMHEMPcl_mZQ1brUjnJXdY', 'https://www.linkedin.com/in/meffazm?miniProfileUrn=urn%3Ali%3Afs_miniProfile%3AACoAADC40OgBcNbVsr02FzlvnKxDnPBVGZL0Stg']\n",
            "Name --> Maxim Smyslov \n",
            "Works At --> Data Scientist at Mars\n",
            "https://www.linkedin.com/in/smyslovmax/\n",
            "Number of posts: 0\n",
            "Name --> ÐÐ»ÐµÐºÑÐ°Ð½Ð´Ñ€ Ð˜Ð²Ð°Ð½Ð¾Ð² \n",
            "Works At --> Data Science/ Data Scientist/ Data Analyst\n",
            "https://www.linkedin.com/in/%D0%B0%D0%BB%D0%B5%D0%BA%D1%81%D0%B0%D0%BD%D0%B4%D1%80-%D0%B8%D0%B2%D0%B0%D0%BD%D0%BE%D0%B2-13540978/\n",
            "Number of posts: 5\n",
            "Post text: Ð° Ð²Ð¾Ñ‚ Ð¸ Ð¾Ð½, Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð½Ð¾Ð¹ Ð´Ð¸Ð¿Ð»Ð¾Ð¼ =))\n",
            "Reactions: Elina Ivanova Ð¸ ÐµÑ‰Ðµ 27Â ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²\n",
            "Post text: Kate Sibrikova, ÑÐ¿Ð°ÑÐ¸Ð±Ð¾ Ð·Ð° Ð¾Ð³Ñ€Ð¾Ð¼Ð½Ñ‹Ð¹ Ð²ÐºÐ»Ð°Ð´! Ð‘Ð»Ð°Ð³Ð¾Ð´Ð°Ñ€Ñ Ñ‚ÐµÐ±Ðµ Ð½Ð°ÑˆÐ° ÐºÐ¾Ð¼Ð°Ð½Ð´Ð° ÑÐ¼Ð¾Ð³Ð»Ð° Ð¿Ð¾Ð¿Ð°ÑÑ‚ÑŒ Ð² Ñ‚Ð¾Ð¿-25% Ð»Ð¸Ð´ÐµÑ€Ð±Ð¾Ñ€Ð´Ð°!\n",
            "Reactions: 9\n",
            "Post text: ÐŸÐ¾ÑÐµÑ‚Ð¸Ð» Ð¾Ñ‡ÐµÐ½ÑŒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ Ð¸ Ð½ÐµÐ¾Ð±Ñ‹Ñ‡Ð½Ð¾Ðµ Ð´Ð»Ñ Ð¼ÐµÐ½Ñ Ð¼ÐµÑ€Ð¾Ð¿Ñ€Ð¸ÑÑ‚Ð¸Ðµ #truetechday Ð¾Ñ‚ #ÐœÐ¢Ð¡. ÐÐ°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¸: #DS , #DE , #DAÐŸÐ¾Ñ€Ð°Ð·Ð¸Ð»Ð¾ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ð¾Ð²:1. Ð Ð°Ð·Ð¼Ð°Ñ…. Ð‘Ñ‹Ð» Ð¾Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð½Ð° Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð¼ÐµÑ€Ð¾Ð¿Ñ€Ð¸ÑÑ‚Ð¸ÑÑ…. ÐÐµÑ‚, ÑÑ‚Ð¾ Ð´Ð°Ð¶Ðµ Ð±Ñ‹Ð»Ð¾ Ð½Ðµ Ð±Ð»Ð¸Ð·ÐºÐ¾. Ð¢ÑƒÑ‚ ÐœÐ¢Ð¡ Ñ€ÐµÑˆÐ¸Ð»Ð¸ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ Ð²Ð»Ð¾Ð¶Ð¸Ñ‚ÑŒÑÑ Ð² ÑÐ°Ð¼Ð¾Ð¿Ð¸Ð°Ñ€. ÐŸÑ€Ð¾Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ, Ñƒ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ð´ÐµÐ»Ð° Ð¸Ð´ÑƒÑ‚ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾, Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÑƒÑ…Ð¾Ð´ÑÑ‚ Ð¾Ñ‚ ÑˆÐ°Ð±Ð»Ð¾Ð½Ð°, ÐœÐ¢Ð¡ Ñ‚ÐµÐ¿ÐµÑ€ÑŒ Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¼Ð¾Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð¾Ð¿ÐµÑ€Ð°Ñ‚Ð¾Ñ€, Ð° Ð¿Ð¾Ð»Ð½Ð¾Ñ†ÐµÐ½Ð½Ð°Ñ ÑÐºÐ¾ÑÐ¸ÑÑ‚ÐµÐ¼Ð°.2. Ð’ÑÐµ ÑÐ¿Ð¸ÐºÐµÑ€Ñ‹, Ð½Ð°Ñ‡Ð¸Ð½Ð°Ñ Ñ Ð¿Ñ€ÐµÐ·Ð¸Ð´ÐµÐ½Ñ‚Ð° ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸, Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¾Ð²Ð°Ð»Ð¸ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ð¸. ÐÐ¸ÐºÐ°ÐºÐ¸Ñ… ÐºÐ¾ÑÑ‚ÑŽÐ¼Ð¾Ð², Ð³Ð°Ð»ÑÑ‚ÑƒÐºÐ¾Ð². Ð”Ð¶Ð¸Ð½ÑÑ‹, Ñ‚Ð¾Ð»ÑÑ‚Ð¾Ð²ÐºÐ°, ÐºÑ€Ð¾ÑÑÐ¾Ð²ÐºÐ¸. 3. Ð’Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ñ Ð¿Ñ€ÐµÐ·Ð¸Ð´ÐµÐ½Ñ‚Ð° ÐœÐ¢Ð¡ Ð’ÑÑ‡ÐµÑÐ»Ð°Ð²Ð° ÐÐ¸ÐºÐ¾Ð»Ð°ÐµÐ²Ð° (Ð²ÑÑ‘, Ð²ÑÐµ Ð¾Ñ‚Ñ‡ÐµÑÑ‚Ð²Ð° Ð¸Ð· Ð²ÑÐµÑ… Ñ€Ð°ÑÐ¿Ð¸ÑÐ°Ð½Ð¸Ð¹ ÑƒÐ¶Ðµ Ð¿Ñ€Ð¾Ð¿Ð°Ð»Ð¸, Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð¼Ñ Ð¸ Ñ„Ð°Ð¼Ð¸Ð»Ð¸Ñ) Ð¸ Ð¸ÑÐ¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð° Ð¿Ð¾ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸ Ð¸ Ð¸Ð½Ð½Ð¾Ð²Ð°Ñ†Ð¸ÑÐ¼ Ð•Ð²Ð³ÐµÐ½Ð¸Ñ Ð§ÐµÑ€ÐµÑˆÐ½ÐµÐ²Ð° Ð±Ñ‹Ð»Ð¸ ÑÑƒÐ¿ÐµÑ€. ÐšÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸ÑŽ Ð½Ð°Ñ‡Ð°Ð»Ð¸ Ñ ÐºÐ¾Ð·Ñ‹Ñ€ÐµÐ¹. Ð¯Ñ€ÐºÐ¾, Ð¶Ð¸Ð²Ð¾, Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾, Ð² ÐºÐ°ÐºÐ¾Ð¹-Ñ‚Ð¾ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚ Ñ Ð·Ð°Ð´ÑƒÐ¼Ð°Ð»ÑÑ: \"Ð° Ñ‡Ñ‚Ð¾ Ñƒ Ð¼ÐµÐ½Ñ Ð¸Ð· Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð¾Ð² Ð¼Ñ‚Ñ, Ñ‚Ð°Ðº, Ð´Ð¾Ð¼Ð°ÑˆÐ½Ð¸Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚, Ð¼Ð¾Ð¶ÐµÑ‚ ÑƒÐ¹Ñ‚Ð¸ Ðº Ð½Ð¸Ð¼ Ñ Ð¼ÐµÐ³Ð°Ñ„Ð¾Ð½Ð° Ð¸ Ð±Ð°Ð½Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ñ Ñ‚Ð¸Ð½ÑŒÐºÐ° Ð½Ð° Ð¼Ñ‚Ñ Ð¿Ð¾Ð¼ÐµÐ½ÑÑ‚ÑŒ?\" ÐŸÐ¾Ñ‚Ð¾Ð¼ ÑÑ‚Ð¾Ñ‚ Ð³Ð¸Ð¿Ð½Ð¾Ð· ÑƒÐ¶Ðµ ÑÐºÐ¸Ð½ÑƒÐ» Ñ ÑÐµÐ±Ñ ðŸ˜ 4. ÐœÐ½Ð¾Ð³Ð¾ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ñ… Ð²Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ð¹, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ DS. Ð”Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ð¹, Ð° Ñ‚Ð°Ðº Ð¶Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚Ð¾Ðº. ÐŸÑ€Ð¸Ñ‡ÐµÐ¼ Ñ€Ð°Ð´ÑƒÐµÑ‚, Ñ‡Ñ‚Ð¾ Ð²ÑÐµ ÑÐ»Ð¾Ð²Ð° ÑƒÐ¶Ðµ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹ ðŸ˜† 5. ChatGPT. ÐÐ°Ð²ÐµÑ€Ð½Ð¾Ðµ, 40% Ð´Ð¾ÐºÐ»Ð°Ð´Ð¾Ð² ÑÐ²Ð¾Ð´Ð¸Ð»Ð¾ÑÑŒ Ðº Ð½ÐµÐ¼Ñƒ. Ð¡Ñ‚Ð¾Ð¸Ñ‚ Ð±Ð¾ÑÑ‚ÑŒÑÑ Ð¸Ð»Ð¸ Ð½ÐµÑ‚? Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð² Ñ€Ð°Ð±Ð¾Ñ‚Ðµ? Ð—Ð°Ñ…Ð²Ð°Ñ‚Ð¸Ñ‚ Ð»Ð¸ Ð¾Ð½ Ð¼Ð¸Ñ€? ÐÐ°ÑÑ‚Ð¾Ð»ÑŒÐºÐ¾ Ð»Ð¸ Ð¾Ð½ ÑÐ»Ð¾Ð¶ÐµÐ½ Ð¸ Ð½ÐµÐ¿Ð¾Ð²Ñ‚Ð¾Ñ€Ð¸Ð¼? Ð’ÑÐµ ÑÐ¿Ð¸ÐºÐµÑ€Ñ‹ Ñ…Ð¾Ñ‚ÐµÐ»Ð¸ Ð²Ñ‹ÑÐºÐ°Ð·Ð°Ñ‚ÑŒÑÑ Ð¾ ÑÐ°Ð¼Ð¾Ð¹ Ð¶Ð¸Ð²Ð¾Ð¹ Ñ‚ÐµÐ¼Ðµ Ð¸ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð»Ð¾ÑÑŒ, Ñ‡Ñ‚Ð¾ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ð»Ð¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¾ Ð½ÐµÐ¼ Ð½Ð° Ð¼Ð½Ð¾Ð³Ð¸Ñ… Ð²Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸ÑÑ…. PS: Ð¿Ð¾ Ð¼Ð½ÐµÐ½Ð¸ÑŽ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð· ÑÐ¿Ð¸ÐºÐµÑ€Ð¾Ð², Ð¶Ð´ÐµÐ¼ Ð² Ð¼Ð°Ñ Ð¾Ñ‚ÐµÑ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¾Ð³6. Ð¡Ð°Ð¼Ð° Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¾Ñ‚ ÐœÐ¢Ð¡. Ð’ÐµÐ»Ð¸ÐºÐ¾Ð»ÐµÐ¿Ð½Ð¾. ÐÐ¸Ð³Ð´Ðµ Ð½ÐµÑ‚ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÐµÐ¹, Ð²ÑÑ‘ Ð±Ñ‹ÑÑ‚Ñ€Ð¾, Ð¿Ñ€Ð¾Ð´ÑƒÐ¼Ð°Ð½Ð½Ð¾. 7. Ð’Ñ‹ÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ñ. Ð ÐµÐ±ÑÑ‚Ð° Ð¾Ñ‡ÐµÐ½ÑŒ Ð¶Ð¸Ð²Ð¾ Ð´ÐµÐ»Ð¸Ð»Ð¸ÑÑŒ ÑÐ²Ð¾Ð¸Ð¼Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°Ð¼Ð¸, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°Ð¼Ð¸, Ñ‡ÐµÐ³Ð¾ Ð´Ð¾Ð±Ð¸Ð»Ð¸ÑÑŒ Ð¸ Ðº ÐºÐ°ÐºÐ¸Ð¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼ Ð¿Ñ€Ð¸ÑˆÐ»Ð¸. ÐŸÐ¾ÑÐ»Ðµ Ð¼ÐµÑ€Ð¾Ð¿Ñ€Ð¸ÑÑ‚Ð¸Ñ Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ð»Ð¸ Ð¾Ð´Ð¸Ð½ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚, Ð° ÐºÑ‚Ð¾ Ñ†ÐµÐ»ÐµÐ²Ð°Ñ Ð°ÑƒÐ´Ð¸Ñ‚Ð¾Ñ€Ð¸Ñ ÑÑ‚Ð¾Ð¹ ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸Ð¸? Ð‘ÑƒÐ´Ð½Ð¸Ð¹ Ð´ÐµÐ½ÑŒ, Ð¾ÑÐ½Ð¾Ð²Ð½Ð°Ñ Ð¼Ð°ÑÑÐ° Ð½Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ðµ, Ñ†ÐµÐ»ÐµÐ½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ð¾ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸ÐºÐ¾Ð² Ð½Ð° Ð¿Ñ€Ð¾Ð¼Ð¾ ÐºÐ¾Ð½Ñ„ÐµÑ€ÐµÐ½Ñ†Ð¸ÑŽ Ð¾Ñ‚ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð¾Ð², ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐµÑ‰Ñ‘ Ð¸ Ð¿ÐµÑ€ÐµÑ…Ð²Ð°Ñ‚Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð³ÑƒÑ‚, Ð²Ñ€ÑÐ´ Ð»Ð¸. Ð—Ð½Ð°Ñ‡Ð¸Ñ‚ Ð¿Ñ€Ð¸Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ‚ÐµÑ…, ÐºÑ‚Ð¾ Ð² Ð¿Ð¾Ð¸ÑÐºÐµ?\n",
            "Reactions: Elina Ivanova Ð¸ ÐµÑ‰Ðµ 17Â ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²\n",
            "Post text: Â«Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ð±ÑƒÐ´ÐµÐ¼ Ñ‡ÐµÑÑ‚Ð½Ñ‹. 91% Ð·Ð°Ð¿Ð°Ð´Ð½Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ð²ÑÐµ ÐµÑ‰Ðµ Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ÑÑ Ð² Ð Ð¾ÑÑÐ¸Ð¸ Ð¸ Ð´ÐµÐ»Ð°ÑŽÑ‚ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ€Ð°Ð·ÑƒÐ¼Ð½Ð¾: Ð¶Ð´ÑƒÑ‚, ÑÐ´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽÑ‚ Ñ€Ð¸ÑÐºÐ¸, Ð·Ð°Ñ‰Ð¸Ñ‰Ð°ÑŽÑ‚ Ð°ÐºÑ‚Ð¸Ð²Ñ‹Â», â€” Ð“Ð»Ð°Ð²Ð° ÐœÐ˜Ð” ÐÐ²ÑÑ‚Ñ€Ð¸Ð¸Ð£ ÐÐ²ÑÑ‚Ñ€Ð¸Ð¸ ÑÐ²Ð¾Ñ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°, Ð¾Ñ‡ÐµÐ½ÑŒ Ð¿Ð¾Ñ…Ð¾Ð¶Ð°Ñ Ð½Ð° ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ Ð² Ð Ð¤, 91% ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹ Ð¾ÑÑ‚Ð°Ð»ÑÑ, Ð½Ð¾ Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ Ð¿Ð¾Ñ‡Ñ‚Ð¸ Ð²ÑÐµÑ… Ð¼Ð¾Ð¸Ñ… Ð·Ð½Ð°ÐºÐ¾Ð¼Ñ‹Ñ…, ÐºÑ‚Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð² Ð´Ð¾Ñ‡ÐºÐ° Ð·Ð°Ð¿Ð°Ð´Ð½Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¹, ÑÐ¾ÐºÑ€Ð°Ñ‚Ð¸Ð»Ð¸? ÐšÑ‚Ð¾-Ñ‚Ð¾ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ ÑÐ´Ð°Ð»ÑÑ, ÐºÑ‚Ð¾-Ñ‚Ð¾ ÑÑ‚Ð°Ñ€Ð°Ð»ÑÑ Ð´Ð¾ ÐºÐ¾Ð½Ñ†Ð°. ÐœÑ‹ ÑÐ»ÐµÐ´Ð¸Ð»Ð¸ Ð·Ð° ÐºÐ°Ð¶Ð´Ñ‹Ð¼ Ð¿Ð°ÐºÐµÑ‚Ð¾Ð¼, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ ÐºÑ‚Ð¾-Ñ‚Ð¾ ÑÐºÐ»Ð°Ð´Ñ‹Ð²Ð°Ð» Ð² Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°ÐºÐµÑ‚Ñ‹.Ð˜Ð·ÑƒÑ‡Ð°Ð»Ð¸ Ð´Ð¾ÑÐºÐ¾Ð½Ð°Ð»ÑŒÐ½Ð¾, Ð¿Ñ‹Ñ‚Ð°ÑÑÑŒ Ð¿Ð¾Ð½ÑÑ‚ÑŒ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸, ÑÐ°Ð¼Ð¸ ÐµÐ²Ñ€Ð¾Ð¿ÐµÐ¹Ñ†Ñ‹ Ð¸Ñ… Ð¸ Ð½Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð»Ð¸. Ð’ Ð½Ð°Ñ‡Ð°Ð»Ðµ Ð±Ñ‹Ð»Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð¿Ð¾ÑÑ‚Ð°Ð²ÐºÐ°Ð¼Ð¸. ÐÐ¸ÐºÑ‚Ð¾ Ð½Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°Ð», Ð¼Ð¾Ð¶Ð½Ð¾/Ð½ÐµÐ»ÑŒÐ·Ñ Ð¸Ð»Ð¸ ÐµÑÐ»Ð¸ Ð¾Ñ‡ÐµÐ½ÑŒ Ñ…Ð¾Ñ‡ÐµÑ‚ÑÑ, Ñ‚Ð¾ Ð¼Ð¾Ð¶Ð½Ð¾. ÐŸÐµÑ€Ð²Ñ‹Ð¹ Ð¿Ð°ÐºÐµÑ‚, Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹, Ñ‚Ñ€ÐµÑ‚Ð¸Ð¹... ÐŸÐ¾Ð¸ÑÐº Ð½Ð¾Ð²Ñ‹Ñ… Ð¿ÑƒÑ‚ÐµÐ¹ Ð»Ð¾Ð³Ð¸ÑÑ‚Ð¸ÐºÐ¸, ÑÑ€Ñ‹Ð² ÑÑ€Ð¾ÐºÐ¾Ð² Ð¿Ð¾ÑÑ‚Ð°Ð²ÐºÐ¸, Ð·Ð°Ð¼ÐµÐ½Ð° Ð¾Ð±Ð¾Ñ€ÑƒÐ´Ð¾Ð²Ð°Ð½Ð¸Ñ Ð² Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐµ Ð¸Ð·Ð³Ð¾Ñ‚Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ, Ð¿Ð¾Ð¸ÑÐº Ð¼ÐµÑÑ‚Ð½Ñ‹Ñ… ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑ‚ÑƒÑŽÑ‰Ð¸Ñ…. Ð’Ñ€Ð¾Ð´Ðµ, Ð¶Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð¶Ð½Ð¾, Ñ€Ð°Ð±Ð¾Ñ‚Ð° ÐºÐ¸Ð¿Ð¸Ñ‚... Ð˜ Ð²Ð¾Ñ‚ Ñ‚ÑƒÑ‚ Ð¿Ñ€Ð¸ÑˆÐµÐ» 7Ð¹ Ð¿Ð°ÐºÐµÑ‚. ÐÐµÑ‡ÐµÑ‚ÐºÐ¸Ðµ Ñ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²ÐºÐ¸: ÐºÑƒÐ´Ð° Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÑ‚ÑŒ, ÐºÑƒÐ´Ð° Ð½ÐµÐ»ÑŒÐ·Ñ, Ñ‡Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð¼Ñ‹ÑˆÐ»ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸, Ð° Ñ‡Ñ‚Ð¾ Ð½ÐµÑ‚, Ð·Ð°Ð²Ð¾Ð´ Ð¸Ð»Ð¸ Ð¸Ð½Ð´ÑƒÑÑ‚Ñ€Ð¸Ñ... ÐÐ¸ÐºÑ‚Ð¾ Ð½Ðµ Ð¼Ð¾Ð³ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ñ‚ÑŒ. Ð®Ñ€Ð¸ÑÑ‚Ñ‹ Ð² Ð•Ð²Ñ€Ð¾Ð¿Ðµ Ñ€Ð°Ð·Ð²Ð¾Ð´Ð¸Ð»Ð¸ Ñ€ÑƒÐºÐ°Ð¼Ð¸. Ð’ÑÐµ Ð·Ð°Ð¿Ð°Ð´Ð½Ñ‹Ðµ Ð³Ð¾ÑÐ¾Ñ€Ð³Ð°Ð½Ñ‹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð¿ÑƒÐ³Ð°Ð½Ñ‹ Ð´Ð°Ð¶Ðµ Ð¿ÐµÑ€ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð¾Ð¹ Ð²Ð·Ð°Ð¸Ð¼Ð¾Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ñ Ð Ð¾ÑÑÐ¸ÐµÐ¹. Ð“Ð¾Ð²Ð¾Ñ€ÑÑ‚, Ð±Ð¸Ð·Ð½ÐµÑ Ð¸ Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð»Ð¸Ñ‡Ð½Ð¾Ð³Ð¾. ÐÐµÑ‚. Ð­Ñ‚Ð¾ Ñ‚Ð°Ðº Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚. Ð‘Ð¸Ð·Ð½ÐµÑ -  ÑÑ‚Ð¾ Ð»Ð¸Ñ‡Ð½Ð¾Ðµ. Ð­Ñ‚Ð¾ Ð»ÑŽÐ´Ð¸. Ð­Ñ‚Ð¾ ÑÐ¼Ð¾Ñ†Ð¸Ð¸!Ð’ÑÐµ Ð¿Ñ‹Ñ‚Ð°Ð»Ð¸ÑÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð±Ð¸Ð·Ð½ÐµÑ. ÐœÐµÐ½ÐµÐ´Ð¶Ð¼ÐµÐ½Ñ‚ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Ð¾Ñ‚ÑÑ‚Ð°Ð¸Ð²Ð°ÐµÑ‚ Ð¾Ñ„Ð¸Ñ  Ð² Ð Ð¤ Ð´Ð¾ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾. ÐŸÐ¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸Ðº. Ð£Ñ‚Ñ€ÐµÐ½Ð½Ð¸Ðµ ÑÐ¾Ð±Ñ€Ð°Ð½Ð¸Ðµ. Ð£Ñ‡Ð°ÑÑ‚Ð²ÑƒÐµÑ‚ Ð¼Ð½Ð¾Ð³Ð¾ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð¾Ð² Ð¸Ð· Ð•Ð²Ñ€Ð¾Ð¿Ñ‹. ÐÐ¸Ñ‡ÐµÐ³Ð¾ Ñ…Ð¾Ñ€Ð¾ÑˆÐµÐ³Ð¾ Ð½Ð°Ð¼ Ð½Ðµ ÑÐºÐ°Ð¶ÑƒÑ‚. Ð˜Ð¼ÐµÐ½Ð½Ð¾ Ñ‚Ð°Ðº. ÐÐ°ÑˆÐ° ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ, ÐºÐ°Ðº Ð¸ Ð¼Ð½Ð¾Ð³Ð¸Ðµ Ð´Ñ€ÑƒÐ³Ð¸Ðµ, Ð¿Ñ€Ð¸Ð½ÑÐ»Ð° Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ ÑƒÑ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ñ Ñ€Ñ‹Ð½ÐºÐ° Ð² Ð Ð¤. Ð¨Ð¾Ðº. Ð”Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑˆÑŒ, Ñ‡Ñ‚Ð¾ Ðº ÑÑ‚Ð¾Ð¼Ñƒ Ð¸Ð´ÐµÑ‚, Ð²ÑÑ‘ Ñ€Ð°Ð²Ð½Ð¾ Ð½ÐµÐ»ÑŒÐ·Ñ Ð±Ñ‹Ñ‚ÑŒ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ð¼. Ð—Ð°Ð¿ÑƒÑÐº Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ°, Ð¼ÐµÐ½ÐµÐ´Ð¶Ð¼ÐµÐ½Ñ‚ ÑÐ¾Ð³Ð»Ð°ÑÑƒÐµÑ‚ ÑÑ€Ð¾ÐºÐ¸, Ð²Ð¾Ð»Ð½Ñ‹ ÑÐ¾ÐºÑ€Ð°Ñ‰ÐµÐ½Ð¸Ð¹, Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¿Ð¾ÑÐ¾Ð±Ð¸Ð¹ - Ð²Ñ€ÐµÐ¼Ñ ÐµÑ‰Ñ‘ ÐµÑÑ‚ÑŒ.ÐšÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð¼Ð¾Ð³Ð»Ð° Ð»ÑŽÐ´ÑÐ¼ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾ - Ð¾Ñ‚ÐºÑ€Ñ‹Ð²Ð°Ð»Ð¸ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð² Ð•Ð²Ñ€Ð¾Ð¿Ðµ. ÐœÐ½Ð¾Ð³Ð¸Ðµ ÐºÐ¾Ð»Ð»ÐµÐ³Ð¸ Ñ€ÐµÑˆÐ¸Ð»Ð¸ÑÑŒ Ð½Ð° Ñ€ÐµÐ»Ð¾ÐºÐ°Ñ†Ð¸ÑŽ. Ð¡Ð»Ð¾Ð¶Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸, Ñ‡ÐµÑ€ÐµÐ· Ð­Ð¼Ð¸Ñ€Ð°Ñ‚Ñ‹ Ð¸Ð· Ð Ð¾ÑÑÐ¸Ð¸ Ð² Ð•Ð²Ñ€Ð¾Ð¿Ñƒ. Ð¯ Ñ‚Ð¾Ð¶Ðµ Ð¿Ñ‹Ñ‚Ð°Ð»ÑÑ. ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ð» Ð¾Ñ„Ñ„ÐµÑ€, Ð½Ð¾, Ð²Ð·Ð²ÐµÑÐ¸Ð² Ð²ÑÐµ Ð·Ð° Ð¸ Ð¿Ñ€Ð¾Ñ‚Ð¸Ð², Ð¾ÑÑ‚Ð°Ð»ÑÑ Ð² Ð Ð¤.Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾ ÐµÐ²Ñ€Ð¾Ð¿ÐµÐ¹ÑÐºÐ¾Ð¼Ñƒ Ð¼ÐµÐ½ÐµÐ´Ð¶Ð¼ÐµÐ½Ñ‚Ñƒ, Ð° Ñ‚Ð°Ðº Ð¶Ðµ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ñƒ Ð¾Ñ„Ð¸ÑÐ° Ð² Ð Ð¾ÑÑÐ¸Ð¸, Ñ€Ð°ÑÑÑ‚Ð°Ð»Ð¸ÑÑŒ Ð´Ð¾ÑÑ‚Ð¾Ð¹Ð½Ð¾. ÐšÑƒÐ»ÑŒÑ‚ÑƒÑ€Ð° Ð² ÐµÐ²Ñ€Ð¾Ð¿ÐµÐ¹ÑÐºÐ¸Ñ… ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸ÑÑ… Ð½Ð° Ð²Ñ‹ÑÐ¾Ñ‚Ðµ Ð¸ ÑÑ‚Ð¾ Ñ‚Ð¾, Ñ‡ÐµÐ¼Ñƒ Ð½Ð°Ð´Ð¾ Ñƒ Ð½Ð¸Ñ… ÑƒÑ‡Ð¸Ñ‚ÑŒÑÑ. ÐŸÐ¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð´ÐµÐ½ÑŒ. Ð’Ñ‚Ð¾Ñ€Ð½Ð¸Ðº. Ð—Ð½Ð°Ð» Ð·Ð°Ñ€Ð°Ð½ÐµÐµ, Ð½Ð¾ Ð²ÑÑ‘ Ñ€Ð°Ð²Ð½Ð¾ Ð¾Ð¿ÑÑ‚ÑŒ ÑˆÐ¾Ðº. 3 ÐºÐ»Ð°ÑÑÐ½Ñ‹Ñ… Ð³Ð¾Ð´Ð° Ð² ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸, Ñ Ð½Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐ» Ñ€ÐµÐ·ÑŽÐ¼Ðµ, Ð½Ðµ Ð¸ÑÐºÐ°Ð» Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ, ÐµÑÐ»Ð¸ Ð¼Ð½Ðµ Ð·Ð²Ð¾Ð½Ð¸Ð»Ð¸ hr, Ñ‚Ð¾ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ð» Ñ‡ÐµÑÑ‚Ð½Ð¾ \"Ð¼Ð½Ðµ Ð½Ðµ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾, Ð½Ð¾ Ð¿Ñ€Ð¸ÑÑ‹Ð»Ð°Ð¹Ñ‚Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ, Ð¿ÐµÑ€ÐµÐºÐ¸Ð½Ñƒ ÐºÐ¾Ð»Ð»ÐµÐ³Ð°Ð¼ Ð¿Ð¾ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŽ\".Ð“Ð´Ðµ-Ñ‚Ð¾ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿ÐµÑ€Ð²Ñ‹Ð¼ Ð¿Ð¾Ð½ÐµÐ´ÐµÐ»ÑŒÐ½Ð¸ÐºÐ¾Ð¼ Ð¸ Ð·Ð°ÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð²Ñ‚Ð¾Ñ€Ð½Ð¸ÐºÐ¾Ð¼ Ð½Ð°Ð´Ð¾ Ð±Ñ‹Ð»Ð¾ Ð´ÑƒÐ¼Ð°Ñ‚ÑŒ, Ñ‡Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ Ð´Ð°Ð»ÑŒÑˆÐµ, Ð° Ð´Ð°Ð»ÑŒÑˆÐµ...\n",
            "Reactions: 28\n",
            "Post text: Ñ‚Ð°Ðº Ð¿Ñ€Ð¸ Ð»ÑŽÐ±Ð¾Ð¼ ÑÑ‚Ð°Ñ€Ñ‚Ðµ =)\n",
            "Reactions: 5\n",
            "Name --> Bogdan Sukhoronchack \n",
            "Works At --> Data scientist / data analyst\n",
            "https://www.linkedin.com/in/bogdan-p-s/\n",
            "Number of posts: 0\n",
            "Name --> Anton Vasilev \n",
            "Works At --> Data scientist\n",
            "https://www.linkedin.com/in/antony-vasilev/\n",
            "Number of posts: 0\n",
            "Name --> Maksim Yuzhakov \n",
            "Works At --> Data Scientist | Data Analyst\n",
            "https://www.linkedin.com/in/yuzhakov-max/\n",
            "Number of posts: 0\n",
            "Name --> Ð¡Ñ‚Ð°Ð½Ð¸ÑÐ»Ð°Ð² Ð¡Ð¸Ð³Ð°Ñ€Ñ‘Ð² \n",
            "Works At --> --\n",
            "https://www.linkedin.com/in/freazer/\n",
            "Number of posts: 0\n",
            "Name --> Denis Dzera \n",
            "Works At --> Data Scientist at Sber\n",
            "https://www.linkedin.com/in/denis-dzera-b26134195/\n",
            "Number of posts: 0\n",
            "Name --> Timur Salakhetdinov \n",
            "Works At --> Financial Data Analyst | SQL | Tableau | TMT Industry | Developed projects for Mobile TeleSystems\n",
            "https://www.linkedin.com/in/stimur/\n",
            "Number of posts: 9\n",
            "Post text: Super excited to share ðŸŽ‰ that I recently had the pleasure of participating in two enriching workshops at YANDEX PRACTICUM ðŸš€. The Yandex Market Hackathon ðŸ§  was a thrilling ride, providing me with my first real-world, cross-functional experience in Data Science ðŸ‘©â€ðŸ’». Our team's spirit ðŸ¤ was truly extraordinary, with everyone committed to helping each other.For the Yandex Market Hackathon https://lnkd.in/dxUzzEmv ðŸ“¦, our goal was to create an ML product for the Yandex Market service packer. Through collaboration, we preprocessed large volumes of raw data ðŸ’½, developing a Machine Learning model that efficiently estimated the best packaging methods. I took up a key role in designing a service algorithm and packer interface for the ML model ðŸ› ï¸, focusing on packaging solutions optimization. As a result, we noticed a significant improvement in packaging efficiency âœ…, positively impacting Yandex Market's operational performance ðŸ“ˆ.In another project, LinkedIn Vacancies Analysis ðŸ•µï¸â€â™‚ï¸, I developed an automated solution to parse LinkedIn vacancies in the Data Analytics field using BeautifulSoup. The initiative aimed to provide deeper insights into market trends and job requirements ðŸ”. Ensuring data consistency and accuracy, I transformed raw scraped data and prepared it for visualization ðŸ–¥ï¸. I also created an interactive dashboard https://lnkd.in/dSxCPqsi using Tableau, which helped identify key skills in demand and map out the competitive landscape in the Data Analytics job market ðŸ“Š.Having tasted the thrill and impact of working in data-driven projects ðŸ’ª, I am  ready to dive headfirst into new opportunities. I am actively seeking roles in Data Analysis or Data Science ðŸŽ¯. With two years of analytics experience under my belt, coupled with my passion for deriving insights from data, I am ready to contribute my skills to a new team and embrace fresh challenges ðŸŒŸ.I'd greatly appreciate any advice or opportunities you may have to share ðŸ™. Thank you in advance for your support! ðŸ˜‰ #dataanalysis #datascience #visualization #tableau #machinelearning #opportunities #job #thankyou\n",
            "Reactions: Oksana Solomentseva Ð¸ ÐµÑ‰Ðµ 1Â ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸Ðº\n",
            "Post text: As an ambitious Data Analyst, my mission is to refine my skill set and knowledge within this exciting field ðŸ‘¨â€ðŸ’». I've recently earned my diploma from the esteemed Yandex Practicum coding bootcamp, specializing in \"Data Analysis\" ðŸ’». This rigorous program has been instrumental in furnishing me with a wealth of experience across a broad spectrum of areas including data preprocessing, exploratory data analysis, business analytics, and cohort analysis using SQL and Python. Additionally, I've honed my skills in A/B testing and visualization through Tableau. This unique blend of training has been indispensable in shaping my understanding of the analytical landscape and has provided me with the tools necessary to tackle complex data-driven problems.I was impressed by the depth and breadth of the skills ðŸŽ“ I've developed. I learned the importance of data preprocessing, and how clean, well-structured data is the foundation of accurate analysis. I also deepened my understanding of the importance of exploratory data analysis in identifying trends and patterns, as well as the powerful insights business analytics and cohort analysis can offer. Finally, I realized that A/B testing isn't just about finding out what works best - it's about understanding why it works best, and applying these findings strategically.Upon finishing ðŸ the Yandex Practicum coding bootcamp I'm grateful for the rigorous training I received through the Yandex Practicum and excited for the opportunities it has opened up for me. The journey of learning never stops, and I can't wait to take my next steps in this exhilarating field of Data Analysis.#dataanalysis #businessanalytics #python #visualization #data #tableau #sql #learning\n",
            "Reactions: 4\n",
            "Post text: I recently found out about a website ADPList, Â which allows people to get free mentorship to boost their professional careers. I had a great session with Younes Sandi! We talked about how to get into Data Science field and he gave me a lot of useful tips. Short session of 30 minutes was really helpful, I now have more clear understanding of the path to take. Younes is very approachable and professional. I recommend ADPList to everyone to find great mentor. #datascience #careers #people\n",
            "Reactions: 5\n",
            "Post text: My Father-in-law sent me this article from Forbes yesterday. Here is a quote from the article that was my main takeaway:\"In fact, as AI becomes more accessible and mainstream, that team (analytics) may well become even more critical to the business than it already is. What is beyond doubt, though, is that their jobs will substantially change.\"The world is changing and we need to adapt with it. Data Analytics is undoubtedly going to change in the next 5-10 years as it adapts to new innovations.Learn the fundamentals now. Learn the new skills being created tomorrow.\n",
            "Reactions: 1Â 364\n",
            "Post text: If you are looking for a great book about statistics that offers a fresh approach to presenting study material and helps you freshen up your knowledge, try OpenIntro Statistics https://lnkd.in/dP-ZDsdZ.What is great about it, is that it is an excellent and free resource for anyone looking to learn about statistics. Also it has an unique approach to presenting the material. Rather than overwhelming the reader with complex formulas and technical jargon, OpenIntro Statistics breaks down concepts in a clear and concise manner, making it accessible to everyone.Another great aspect of this book is the numerous tasks and exercises at the end of each section. These exercises help solidify the concepts covered in the section and give readers a chance to practice what they have learned. I found information about OpenIntro Statistics on a post made by Nick Singh ðŸ“•ðŸ’ and recommend it too for anyone looking to learn more about statistics or freshen up their knowledge.#dataanalyst #datascientist #statisticsÂ #education\n",
            "Post text: According to the latest MIT study ChatGPT boosts productivity by 40% and quality by 20%. One of the most exciting findings from the study was that exposure to ChatGPT increased job satisfaction and self-efficacy. With the ability to enhance productivity, diminish inequality, and narrow the distribution of productivity, ChatGPT possesses the potential to bring about a revolutionary shift in the way we approach work, particularly within the realm of writing. By predominantly supplanting worker effort as opposed to simply supplementing worker skills, ChatGPT has reorganized task assignments to prioritize activities such as idea-generation and editing, while de-emphasizing the more rudimentary task of rough-drafting.How do you personally use ChatGPT? I think it really can help any professional increase their productivity, especially when you need to do a lot of drafts of text. With the help of ChatGPT, you get a first raw draft in 1 second! Itâ€™s just amazing how it works.Other use cases for me were to compare services on the web. It can create in an instant a table of all features available by 2-3 services.The last use case I would like to mention is that ChatGPT can substantially help with preparation for interviews.#productivity #writing #chatgpt #editing\n",
            "Reactions: 2\n",
            "Post text: As an aspiring Data Analyst, I am constantly striving to improve my skills and knowledge in the field ðŸ‘¨â€ðŸ’». Last year, I had the opportunity to participate in the Yandex Practicum coding bootcamp Â«Specialist in Data ScienceÂ» ðŸ’», where I gained invaluable experience in data cleaning, management, transformation, visualization, statistical and data analysis, and machine learning.Throughout the program, I learned various techniques and tools that have helped me enhance my skills and become a better Data Analyst. The hands-on projects and assignments gave me the chance to practice my skills and apply the knowledge I gained in real-world scenarios.One of the most significant takeaways from the program was learning how to handle and clean messy data. This is an essential skill for any Data Analyst, as working with raw and unorganized data can be a challenging task.The program was incredibly rigorous, but I'm grateful for the challenges it presented. By the end of the program, I felt confident in my ability to work with complex data sets and to use various tools and techniques to derive meaningful insights from them.Since completing the program, I'm excited to continue to grow and develop as a Data Analyst and currently continue my studies at Yandex Practicum Â«Data AnalyticsÂ» bootcamp ðŸ˜‰.#machinelearning #datascience #dataanalysis #python #bootcamp #like\n",
            "Reactions: 2\n",
            "Post text: I just finished an updated Machine Learning Specialization! Thank you Andrew Ng and DeepLearning.AI for this wonderful opportunity! I think Andrew Ng is one of the best instructors, who easily explains complex topics about ML. This is a foundational program on ML, so if you want to improve the understanding of basic AI concepts, go for it. You will get a broad introduction to: - supervised learning (linear regression, logistic regression, gradient descent),- advanced algorithms (neural networks, decision trees)- unsupervised learning (clustering, anomaly detection, PCA), recommender systems, reinforcement learning.I hope that you will have same fun, exploring this course, if you choose it too!#datascientist #dataanalyst #machinelearning #deeplearning #ai #neuralnetworksÂ #thankyou #learning\n",
            "Reactions: 2\n",
            "Name --> Ð˜Ð²Ð°Ð½ Ð“Ð¾Ñ€Ð±ÑƒÐ½Ð¾Ð² \n",
            "Works At --> Data Scientist â€“ MTS\n",
            "https://www.linkedin.com/in/ivan-gorbunov-h/\n",
            "Number of posts: 0\n",
            "Name --> Fedor Mushenok \n",
            "Works At --> ML developer at Yandex\n",
            "https://www.linkedin.com/in/fedor-mushenok/\n",
            "Number of posts: 3\n",
            "Post text: Hi everyone - I am looking for a new role and would appreciate your support. Thank you in advance for any connections, advice, or opportunities you can offer. #OpenToWork\n",
            "Reactions: 19\n",
            "Post text: #inspiration #philips\n",
            "Reactions: 2\n",
            "Name --> Ð’Ð»Ð°Ð´Ð¸Ð¼Ð¸Ñ€ ÐÐ¿ÐµÑ€ÑÐ½ \n",
            "Works At --> Data Scientist\n",
            "https://www.linkedin.com/in/vladimir-aperyan/\n",
            "Number of posts: 0\n",
            "Name --> Svyatoslav Emelyanenko \n",
            "Works At --> Data Scientist â€“ Ð“Ð°Ð·Ð¿Ñ€Ð¾Ð¼Ð±Ð°Ð½Ðº\n",
            "https://www.linkedin.com/in/svit/\n",
            "Number of posts: 0\n",
            "Name --> ÐÐ½Ð°ÑÑ‚Ð°ÑÐ¸Ñ ÐÐµÑ‡Ð¸Ð¿Ð¾Ñ€ÐµÐ½ÐºÐ¾ \n",
            "Works At --> Data Scientist\n",
            "https://www.linkedin.com/in/anechiporenko/\n",
            "Number of posts: 1\n",
            "Post text: My first step into the world of data science :)\n",
            "Reactions: 13\n",
            "Name --> Dmitrii Velibekov \n",
            "Works At --> Data Scientist at OTP Bank\n",
            "https://www.linkedin.com/in/meffazm/\n",
            "Number of posts: 3\n",
            "Reactions: 2\n",
            "Reactions: 4\n",
            "Reactions: 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "profile_urls = list(set(profile_urls))\n",
        "\n",
        "print(profile_urls)\n",
        "\n",
        "# Parse profile urls\n",
        "for profile_url in profile_urls:\n",
        "    get_and_print_profile_info(driver, profile_url)\n",
        "    time.sleep(2)\n",
        "\n",
        "# close the Chrome browser\n",
        "driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_and_print_profile_info(driver, profile_url):\n",
        "    driver.get(profile_url)        # this will open the link\n",
        "\n",
        "    # Extracting data from page with BeautifulSoup\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml')\n",
        "\n",
        "    # Extracting the HTML of the complete introduction box\n",
        "    # that contains the name, company name, and the location\n",
        "    intro = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
        "\n",
        "    #print(intro)\n",
        "\n",
        "    # In case of an error, try changing the tags used here.\n",
        "    name_loc = intro.find(\"h1\")\n",
        "\n",
        "    # Extracting the Name\n",
        "    name = name_loc.get_text().strip()\n",
        "    # strip() is used to remove any extra blank spaces\n",
        "\n",
        "    works_at_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
        "\n",
        "    # this gives us the HTML of the tag in which the Company Name is present\n",
        "    # Extracting the Company Name\n",
        "    works_at = works_at_loc.get_text().strip()\n",
        "\n",
        "    print(\"Name -->\",  name,\n",
        "          \"\\nWorks At -->\", works_at)\n",
        "\n",
        "    POSTS_URL_SUFFIX = 'recent-activity/all/'\n",
        "\n",
        "    time.sleep(0.5)\n",
        "\n",
        "    # Get current url from browser\n",
        "    cur_profile_url = driver.current_url\n",
        "    print(cur_profile_url)\n",
        "\n",
        "    # Parse posts\n",
        "    get_and_print_user_posts(driver, cur_profile_url + POSTS_URL_SUFFIX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\1837785477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_profile_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\4143096644.py\u001b[0m in \u001b[0;36mget_and_print_profile_info\u001b[1;34m(driver, profile_url)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# In case of an error, try changing the tags used here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mname_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Extracting the Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
          ]
        }
      ],
      "source": [
        "get_and_print_profile_info(driver, profile_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_and_print_profile_info(driver, profile_url):\n",
        "    time.sleep(random.uniform(0,2))\n",
        "\n",
        "    driver.get(profile_url)        # this will open the link\n",
        "\n",
        "    # Extracting data from page with BeautifulSoup\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml') # 'lxml'  \"html.parser\"\n",
        "\n",
        "    # Extracting the HTML of the complete introduction box\n",
        "    # that contains the name, company name, and the location\n",
        "    intro = soup.find('div', {'class': 'pv-text-details__left-panel'})\n",
        "\n",
        "    #print(intro)\n",
        "\n",
        "    # In case of an error, try changing the tags used here.\n",
        "    name_loc = intro.find(\"h1\")\n",
        "\n",
        "    # Extracting the Name\n",
        "    name = name_loc.get_text().strip()\n",
        "    # strip() is used to remove any extra blank spaces\n",
        "\n",
        "    works_at_loc = intro.find(\"div\", {'class': 'text-body-medium'})\n",
        "\n",
        "    # this gives us the HTML of the tag in which the Company Name is present\n",
        "    # Extracting the Company Name\n",
        "    works_at = works_at_loc.get_text().strip()\n",
        "\n",
        "    print(\"Name -->\",  name,\n",
        "          \"\\nWorks At -->\", works_at)\n",
        "\n",
        "    POSTS_URL_SUFFIX = 'recent-activity/all/'\n",
        "\n",
        "    time.sleep(random.uniform(2,4))\n",
        "\n",
        "    # Get current url from browser\n",
        "    cur_profile_url = driver.current_url\n",
        "    print(cur_profile_url)\n",
        "\n",
        "    # Parse posts\n",
        "    posts = get_and_print_user_posts(driver, cur_profile_url + POSTS_URL_SUFFIX)\n",
        "    \n",
        "    return name, works_at, posts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'find'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\1837785477.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_profile_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\3012557116.py\u001b[0m in \u001b[0;36mget_and_print_profile_info\u001b[1;34m(driver, profile_url)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# In case of an error, try changing the tags used here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mname_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintro\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"h1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Extracting the Name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
          ]
        }
      ],
      "source": [
        "get_and_print_profile_info(driver, profile_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qyTOHOUtzwNk"
      },
      "outputs": [],
      "source": [
        "def get_and_print_user_posts(driver, posts_url):\n",
        "    driver.get(posts_url)\n",
        "\n",
        "    #Simulate scrolling to capture all posts\n",
        "    SCROLL_PAUSE_TIME = 1.5\n",
        "\n",
        "    # Get scroll height\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "\n",
        "    # We can adjust this number to get more posts\n",
        "    NUM_SCROLLS = 5\n",
        "\n",
        "    for i in range(NUM_SCROLLS):\n",
        "        # Scroll down to bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "\n",
        "        # Wait to load page\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "        # Calculate new scroll height and compare with last scroll height\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "        last_height = new_height\n",
        "\n",
        "    # Parsing posts\n",
        "    src = driver.page_source\n",
        "\n",
        "    # Now using beautiful soup\n",
        "    soup = BeautifulSoup(src, 'lxml')\n",
        "    # soup.prettify()\n",
        "\n",
        "    posts = soup.find_all('li', class_='profile-creator-shared-feed-update__container')\n",
        "    # print(posts)\n",
        "\n",
        "    print(f'Number of posts: {len(posts)}')\n",
        "    for post_src in posts:\n",
        "        post_text_div = post_src.find('div', {'class': 'feed-shared-update-v2__description-wrapper mr2'})\n",
        "\n",
        "        # if post_text_div is None:\n",
        "        #     print(post_src)\n",
        "\n",
        "        if post_text_div is not None:\n",
        "            post_text = post_text_div.find('span', {'dir': 'ltr'})\n",
        "        else:\n",
        "            post_text = None\n",
        "\n",
        "        # If post text is found\n",
        "        if post_text is not None:\n",
        "            post_text = post_text.get_text().strip()\n",
        "            print(f'Post text: {post_text}')\n",
        "\n",
        "        reaction_cnt = post_src.find('span', {'class': 'social-details-social-counts__reactions-count'})\n",
        "\n",
        "        # If number of reactions is written as text\n",
        "        # It has different class name\n",
        "        if reaction_cnt is None:\n",
        "            reaction_cnt = post_src.find('span', {'class': 'social-details-social-counts__social-proof-text'})\n",
        "\n",
        "        if reaction_cnt is not None:\n",
        "            reaction_cnt = reaction_cnt.get_text().strip()\n",
        "            print(f'Reactions: {reaction_cnt}')\n",
        "\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'posts_url' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\4129543028.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_and_print_user_posts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposts_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'posts_url' is not defined"
          ]
        }
      ],
      "source": [
        "get_and_print_user_posts(driver, posts_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "PYmDuQr2z7q4",
        "outputId": "b4a25b5d-b93c-4b70-acc5-07bc7f4f1240"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'selenium.webdriver' has no attribute 'ChromOptions'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14316\\3169853951.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcaps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pageLoadStrategy'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'eager'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChromOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enable-automation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m#options.add_argument(\"--no-sandbox\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'selenium.webdriver' has no attribute 'ChromOptions'"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    # start Chrome browser\n",
        "    caps = DesiredCapabilities().CHROME\n",
        "\n",
        "    caps['pageLoadStrategy'] = 'eager'\n",
        "\n",
        "    options = webdriver.ChromOptions()\n",
        "    options.add_argument('enable-automation')\n",
        "    #options.add_argument(\"--no-sandbox\")\n",
        "    #options.add_argument(\"--disable-setuid-sandbox\")\n",
        "\n",
        "    driver = webdriver.Chrome(options = options)\n",
        "\n",
        "    # Opening linkedIn's login page\n",
        "    # NOTE: We need to turn of 2 step authentification\n",
        "    driver.get(\"https://linkedin.com/uas/login\")\n",
        "\n",
        "    # waiting for the page to load\n",
        "    time.sleep(3.5)\n",
        "\n",
        "    # entering username\n",
        "    username = driver.find_element(By.ID, \"username\")\n",
        "\n",
        "    # In case of an error, try changing the element\n",
        "    # tag used here.\n",
        "\n",
        "    # Enter Your Email Address\n",
        "    username.send_keys(USER_LOGIN)\n",
        "\n",
        "    # entering password\n",
        "    pword = driver.find_element(By.ID, \"password\")\n",
        "    # In case of an error, try changing the element\n",
        "    # tag used here.\n",
        "\n",
        "    # Enter Your Password\n",
        "    pword.send_keys(USER_PASSWORD)\n",
        "\n",
        "    # Clicking on the log in button\n",
        "    # Format (syntax) of writing XPath -->\n",
        "    # //tagname[@attribute='value']\n",
        "    driver.find_element(By.XPATH, \"//button[@type='submit']\").click()\n",
        "\n",
        "    ### TEST for parsing page with posts\n",
        "    # get_and_print_profile_info(driver, 'https://www.linkedin.com/in/mathurin-ache-11004218')\n",
        "\n",
        "    # exit()\n",
        "\n",
        "    # Open search page\n",
        "    driver.get('https://www.linkedin.com/search/results/people/?keywords=data%20scientist&origin=CLUSTER_EXPANSION&sid=1gy')\n",
        "\n",
        "    profile_urls = []\n",
        "\n",
        "    NUM_PAGES_TO_PARSE = 12\n",
        "\n",
        "    # Iterate over pages of search results\n",
        "    # to collect profile urls\n",
        "    for i in range(NUM_PAGES_TO_PARSE):\n",
        "        search_result_links = driver.find_elements(By.CSS_SELECTOR, \"div.entity-result__item a.app-aware-link\")\n",
        "\n",
        "        for link in search_result_links:\n",
        "            href = link.get_attribute(\"href\")\n",
        "            if 'linkedin.com/in' in href:\n",
        "                profile_urls.append(href)\n",
        "\n",
        "        next_button = driver.find_element(By.CLASS_NAME,'artdeco-pagination__button--next')\n",
        "        next_button.click()\n",
        "        time.sleep(2)\n",
        "\n",
        "\n",
        "    profile_urls = list(set(profile_urls))\n",
        "\n",
        "    print(profile_urls)\n",
        "\n",
        "    # Parse profile urls\n",
        "    for profile_url in profile_urls:\n",
        "        get_and_print_profile_info(driver, profile_url)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # close the Chrome browser\n",
        "    driver.quit()"
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 6869,
        "start_time": "2023-06-26T09:53:26.717Z"
      },
      {
        "duration": 52,
        "start_time": "2023-06-26T09:54:00.330Z"
      },
      {
        "duration": 3176,
        "start_time": "2023-06-26T09:54:06.302Z"
      },
      {
        "duration": 4421,
        "start_time": "2023-06-26T09:54:12.202Z"
      },
      {
        "duration": 299,
        "start_time": "2023-06-26T09:54:17.434Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-26T09:54:32.258Z"
      },
      {
        "duration": 28,
        "start_time": "2023-06-26T09:54:51.234Z"
      },
      {
        "duration": 1362,
        "start_time": "2023-06-26T09:55:45.641Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T09:58:27.798Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:27:42.712Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:28:15.154Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-26T10:28:37.419Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:28:43.796Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:28:51.407Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:08.234Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:51:25.096Z"
      },
      {
        "duration": 12,
        "start_time": "2023-06-26T10:51:30.127Z"
      },
      {
        "duration": 11,
        "start_time": "2023-06-26T10:51:35.208Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:39.600Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:44.939Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:51:50.421Z"
      },
      {
        "duration": 657,
        "start_time": "2023-06-26T10:52:26.923Z"
      },
      {
        "duration": 8,
        "start_time": "2023-06-26T10:53:02.146Z"
      },
      {
        "duration": 4,
        "start_time": "2023-06-26T10:54:04.427Z"
      },
      {
        "duration": 10,
        "start_time": "2023-06-26T10:54:10.406Z"
      },
      {
        "duration": 113,
        "start_time": "2023-06-26T10:57:42.853Z"
      },
      {
        "duration": 118,
        "start_time": "2023-06-26T10:57:49.217Z"
      }
    ],
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
